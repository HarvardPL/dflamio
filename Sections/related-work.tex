We consider three categories of related work: First, we discuss relations to other projects applying FLAM to model trust relationships in programming languages. Second, we discuss various extensions of LIO related to distributed computation and coarse-grained information flow. Finally, we relate \lang{} to other works modelling remote procedure call for distributed computation.

\paragraph{FLAM}
The FLAM technical report \cite{flamtr} presents a security-typed language $\mathsf{F}\lambda$ in which policies are FLAM principals. Much like \lang{}, $\mathsf{F}\lambda$ can delegate trust during evaluation and allows querying of trust relationships. However, the decision of whether or not to allow downgrading (ie., adding new trust relationships) must be performed statically using a relatively simple type system. In \lang{} all decisions about whether to allow downgrading is done during evaluation, meaning that \lang{} can potentially allow more downgrading and remain secure.

FLAC \cite{7536372} is a calculus for flow-limited authorization, which allows static reasoning about mechanisms such as commitment schemes or bearer credentials that require dynamic authorization. FLAC builds a sophisticated type system on top of FLAM and proves noninterference and robust declassification properties for the language. While FLAC offers many high level features necessary to build usable authorization mechanisms, it uses a limited subset of FLAM (ie., it does not have a rule equivalent to FLAM's \ruleref{Fwd} rule for distributed trust checking). Furthermore, FLAC does not consider evaluation with side effects (other than adding trust relationship) and does not include convenient imperative features found in many languages like mutable references.

Hyperflow \cite{hyperflow} is a new processor architecture for nonmalleable, timing-sensitive information-flow control that uses FLAM principals encoded as bitvectors as the label model. This encoding offers efficient computation of joins, meets and projections. Using this encoding Hyperflow extends the RISC-V processor with information-flow control instructions and limits how information flows through registers and memory pages. The hardware can be programmed in a new hardware-description language called ChiselFlow embedded in Scala. Much like \lang{}, each process in a Hyperflow processor contains a current label and a clearance label, but unlike our model Hyperflow requires that the programmer to explicitly raise the current label. This decision avoids the possible side-channel caused by raising the current label depending on sensitive information, at the cost of putting the burden of raising the label on the programmer.

\paragraph{LIO and coarse-grained information-flow}
The original formulation of LIO \cite{SRMMlio} has been extended in many dimensions. Concurrent LIO \cite{Stefan:2012:ACT:2364527.2364557} extends LIO with concurrency primitives such as forking and synchronization. As computation is concurrent in this language the termination-channel is amplifiable and must be closed. In \cite{Stefan:2012:ACT:2364527.2364557} the authors shows that LIO can be shown to satisfy termination-sensitive noninterference by removing the $\tolabeledkw$ primitive from the language. This is detrimental to the usability of LIO, and thus \cite{Stefan:2012:ACT:2364527.2364557} introduces a version of $\tolabeledkw$ that is safe in a concurrent setting. Intuitively, the dangerous part of $\tolabeledkw$ is that one can perform synchronization across threads inside a $\tolabeledkw$, and then leak via an internal timing attack. The solution to this problem is that a concurrent version of $\tolabeledkw$ should spawn a new thread, and not raise the current label until synchronization is performed. In \lang{} it is secure to have a simple $\tolabeledkw$ construct as internal timing attacks is not possible. This means label creep can be mitigated by the same techniques that programmers already know from \cite{SRMMlio}.

Recent work \cite{Rajani:2017:TSI:3051528.3051531} on the expressiveness of fine-grained versus coarse-grained information flow shows that the two approaches has the same expressive power, and the authors of \cite{Rajani:2017:TSI:3051528.3051531} suggest preferring coarse-grained information flow tracking as opposed to fine-grained information-flow tracking, as the former puts less burden on the programmer. Based on our experience with \lang{}, we agree with this observation.

\paragraph{Remote procedure call and distributed computation}
Our model for remote procedure calls is inspired by the work in \cite{10.1007/978-3-642-25462-8_28} which presents a Location-aware Simple Abstract Machine (LSAM). In our terminology, a global LSAM configuration is a set of local LSAM configurations indexed by names. A remote procedure call is performed by suspending the computation and transferring control to another local LSAM configuration. While \cite{10.1007/978-3-642-25462-8_28} considers a first-order language useful as a target language for compiling other languages for distributed computation, our semantics handles higher-order functions in the style of the source language in \cite{Cooper:2009:RC:1599410.1599439}, and LSAM would be a natural compilation target for our work.